{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74093802-0a02-443a-a4f6-8ec49044317c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "from bertopic import BERTopic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import nltk\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28747dd1-4612-4db2-9505-0ba523eadf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only the topics of interest\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('tweet_with_topics_sentiment.csv')\n",
    "\n",
    "# Define the topics of interest\n",
    "topics_of_interest = [1, 2, 3, 4, 5, 6, 8, 9]\n",
    "\n",
    "# Filter the dataset \n",
    "filtered_data = data[data['topic'].isin(topics_of_interest)]\n",
    "\n",
    "# Create a mapping from original topics to new encoded values\n",
    "topic_mapping = {topic: i for i, topic in enumerate(sorted(topics_of_interest))}\n",
    "\n",
    "# Apply the mapping to the 'topic' column\n",
    "filtered_data['topic'] = filtered_data['topic'].replace(topic_mapping)\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "filtered_data.to_csv('filtered_tweet_with_topics_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5298565-ec7d-45f1-a371-82bb740f98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16243ac-6336-4406-b304-e517b63a26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"filtered_tweet_with_topics_sentiment.csv\")\n",
    "\n",
    "# First split: Separate out the test data from the initial dataset\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)  # 20% for testing\n",
    "\n",
    "# Second split: Divide the training dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # 25% of 80% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c89107-eb5e-4c29-9e63-c07321e25ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for handling tweet data\n",
    "class TweetDataset(Dataset):\n",
    "    \n",
    "    # Initialization with DataFrame, tokenizer, and optional max length\n",
    "    def __init__(self, dataframe, tokenizer, max_length=150):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = dataframe['clean_tweet'].values.tolist()  \n",
    "        self.labels = dataframe['topic'].values  \n",
    "        self.max_length = max_length\n",
    "        \n",
    "    # Return the total number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    # Retrieve an item by its index\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Prepare item with input IDs and attention mask\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),  \n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n",
    "        \n",
    "        # Include labels if available\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  \n",
    "        \n",
    "        return item\n",
    "\n",
    "    # Print random samples from the dataset to check data\n",
    "    def _print_random_samples(self, texts):\n",
    "        import numpy as np\n",
    "        np.random.seed(42)\n",
    "        random_entries = np.random.randint(0, len(texts), 5)\n",
    "\n",
    "        for i in random_entries:\n",
    "            print(f\"Entry {i}: {texts[i]}\")\n",
    "            \n",
    "    # Comprehensive text preprocessing\n",
    "    def _preprocess(self, text):\n",
    "        text = self._remove_amp(text)\n",
    "        text = self._remove_links(text)\n",
    "        text = self._remove_hashes(text)\n",
    "        text = self._remove_retweets(text)\n",
    "        text = self._remove_mentions(text)\n",
    "        text = self._remove_multiple_spaces(text)\n",
    "\n",
    "        #text = self._lowercase(text)\n",
    "        text = self._remove_punctuation(text)\n",
    "        #text = self._remove_numbers(text)\n",
    "\n",
    "        text_tokens = self._tokenize(text)\n",
    "        text_tokens = self._stopword_filtering(text_tokens)\n",
    "        #text_tokens = self._stemming(text_tokens)\n",
    "        text = self._stitch_text_tokens_together(text_tokens)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    # Helper methods for preprocessing: remove special characters, links, hashtags, etc.\n",
    "    def _remove_amp(self, text):\n",
    "        return text.replace(\"&amp;\", \" \")\n",
    "\n",
    "    def _remove_mentions(self, text):\n",
    "        return re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    \n",
    "    def _remove_multiple_spaces(self, text):\n",
    "        return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    def _remove_retweets(self, text):\n",
    "        return re.sub(r'^RT[\\s]+', ' ', text)\n",
    "\n",
    "    def _remove_links(self, text):\n",
    "        return re.sub(r'https?:\\/\\/[^\\s\\n\\r]+', ' ', text)\n",
    "\n",
    "    def _remove_hashes(self, text):\n",
    "        return re.sub(r'#', ' ', text)\n",
    "\n",
    "    def _stitch_text_tokens_together(self, text_tokens):\n",
    "        return \" \".join(text_tokens)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        return nltk.word_tokenize(text, language=\"english\")\n",
    "\n",
    "    def _stopword_filtering(self, text_tokens):\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        return [token for token in text_tokens if token not in stop_words]\n",
    "\n",
    "    def _stemming(self, text_tokens):\n",
    "        porter = nltk.stem.porter.PorterStemmer()\n",
    "        return [porter.stem(token) for token in text_tokens]\n",
    "\n",
    "    def _remove_numbers(self, text):\n",
    "        return re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    def _lowercase(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def _remove_punctuation(self, text):\n",
    "        return ''.join(character for character in text if character not in string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748ca49-7248-461b-891a-c7eacfe82200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device based on the availability of CUDA (GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(TweetClassifier, self).__init__()\n",
    "        self.bert = base_model\n",
    "        self.fc1 = nn.Linear(768, 32)\n",
    "        self.fc2 = nn.Linear(32, 8)  # Output for 8 classes\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0][:, 0]\n",
    "        x = self.fc1(bert_out)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e9fb2-fdda-4b11-a6d9-03d7cf5cedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA operations to be synchronous to facilitate easier debugging of CUDA errors\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d29df-4a9b-4463-93ea-657061e454b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training: initialize device, loss function, optimizer, and set initial tracking metrics for early stopping.\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, learning_rate, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for train_input in tqdm(train_dataloader):\n",
    "            input_ids = train_input['input_ids'].to(device)\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            train_label = train_input['labels'].to(device)\n",
    "\n",
    "           \n",
    "            print(\"Unique train labels:\", torch.unique(train_label))\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            loss = criterion(output, train_label)\n",
    "\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)  # Get predicted classes\n",
    "            acc = (predicted == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            for val_input in tqdm(val_dataloader):\n",
    "                input_ids = val_input['input_ids'].to(device)\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                val_label = val_input['labels'].to(device)\n",
    "\n",
    "                print(\"Unique val labels:\", torch.unique(val_label))\n",
    "\n",
    "                output = model(input_ids, attention_mask)\n",
    "                loss = criterion(output, val_label)\n",
    "\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                acc = (predicted == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "            \n",
    "            print(f'Epochs: {epoch + 1} '\n",
    "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
    "                  f'| Train Accuracy: {total_acc_train / len(train_dataloader.dataset): .3f} '\n",
    "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
    "                  f'| Val Accuracy: {total_acc_val / len(val_dataloader.dataset): .3f}')\n",
    "            \n",
    "            if best_val_loss > total_loss_val:\n",
    "                best_val_loss = total_loss_val\n",
    "                torch.save(model.state_dict(), \"best_model_topic.pt\")  # Save only the model's parameters\n",
    "                print(\"Saved model\")\n",
    "                early_stopping_threshold_count = 0\n",
    "            else:\n",
    "                early_stopping_threshold_count += 1\n",
    "                \n",
    "            if early_stopping_threshold_count >= 3:  # Early stopping threshold\n",
    "                print(\"Early stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc36c8-897e-4844-a5a3-6963aeaa6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources, set random seeds for reproducibility\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    " \n",
    "# initialize tokenizer and model     \n",
    "BERT_MODEL = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "base_model_topic = AutoModel.from_pretrained(BERT_MODEL)\n",
    "\n",
    "# prepare data loaders\n",
    "train_dataloader = DataLoader(TweetDataset(train_df, tokenizer), batch_size=8, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(TweetDataset(val_df, tokenizer), batch_size=8, num_workers=0)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "    print(\"Input IDs shape:\", input_ids.shape)  \n",
    "    print(\"Attention Mask shape:\", attention_mask.shape)  \n",
    "    print(\"Labels shape:\", labels.shape)  \n",
    "    print(\"Unique labels in batch:\", torch.unique(labels))  \n",
    "    break  \n",
    "\n",
    "model = TweetClassifier(base_model_topic)\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epochs = 5\n",
    "train(model, train_dataloader, val_dataloader, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2f785-9622-47cb-86ae-05c6d5766901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Model \n",
    "model = TweetClassifier(base_model_topic) \n",
    "model.load_state_dict(torch.load(\"best_model_topic.pt\")) \n",
    "model.to(device)  \n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0daac3-73d5-4b4b-b076-44fbccf2fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Predictions\n",
    "\n",
    "def get_text_predictions(model, loader):\n",
    "    model.eval()  \n",
    "    results_predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            predicted_classes = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            results_predictions.extend(predicted_classes.tolist())\n",
    "            actual_labels.extend(labels.tolist())\n",
    "    \n",
    "    return results_predictions, actual_labels\n",
    "\n",
    "test_dataloader = DataLoader(TweetDataset(test_df, tokenizer), batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = get_text_predictions(model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9e139-46d7-445c-8948-653896922c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print performance metrics (accuracy, precision, recall, F1-score) for the model's predictions.\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783045d-309d-43e0-8f64-15db545e16f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
