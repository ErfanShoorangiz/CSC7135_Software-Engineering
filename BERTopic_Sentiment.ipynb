{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0df613a-7555-4a8e-8a94-01284afd4c7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1629794-e797-4343-93ae-d2291ea45f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9002217-bcc9-4965-b882-e47838524fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a2ae8-400d-42c1-8d17-4b7726c8916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c2d23-b43a-4012-b36a-a435bfabc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function for tweets\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    \"\"\"Preprocess a tweet by normalizing various elements.\"\"\"\n",
    "    # Replace Twitter handles with '@user'\n",
    "    tweet = re.sub(r'@\\w+', '@user', tweet)\n",
    "    \n",
    "    # Replace URLs with 'http'\n",
    "    tweet = re.sub(r'http\\S+', 'http', tweet) \n",
    "    return tweet\n",
    "\n",
    "# Apply preprocessing to each tweet in the DataFrame\n",
    "data['clean_tweet'] = data['tweet'].apply(preprocess_tweet)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52694c76-9aa2-4b28-b151-01b92c5a88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment analysis model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4f92e-6332-46b5-8280-f7b5add5c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2190591-d3fc-48bd-ad03-bd785d934f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BERTopic\n",
    "\n",
    "# Set environment variable for tokenizers to avoid parallelism issues\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Use 'clean_tweet' for BERTopic and sentiment analysis\n",
    "docs = data['clean_tweet'].tolist()\n",
    "\n",
    "# Create and apply BERTopic model\n",
    "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Fit the model\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Explore the topics\n",
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "# Add the topics to the DataFrame\n",
    "data['topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d9e34-005b-495d-b6c2-56dc7b2714b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment scores\n",
    "def get_sentiment_scores(tweet):\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt', max_length=512, truncation=True)\n",
    "    encoded_tweet = {k: v.to(device) for k, v in encoded_tweet.items()}\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_tweet)\n",
    "    scores = output[0][0].cpu().detach().numpy()\n",
    "    return softmax(scores)\n",
    "\n",
    "# Apply sentiment analysis and add scores to DataFrame\n",
    "data[['negative', 'neutral', 'positive']] = data['clean_tweet'].apply(lambda x: pd.Series(get_sentiment_scores(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542d8d9-888f-4aae-93c1-fdf67b44730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with topics and sentiment analysis to a new CSV file\n",
    "data.to_csv('tweet_with_topics_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67469a-dd59-420c-9cd9-224c49313e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd1c6c-6b81-4eeb-bbac-eb7a8f5eef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7bf34-3508-4363-a86e-22e003aa4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 10 topics\n",
    "topic_info_df = topic_model.get_topic_info()\n",
    "top_10_topics = topic_info_df.head(11)  # The first topic (-1) is the outlier topic\n",
    "print(top_10_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275c2e4-dfcc-4707-8db4-37b44e52bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b7572-a361-4411-a928-183f6309f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380119f-b059-41ed-a0bd-bb15a7a1cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"topic\": topics, \"document\": docs})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52966a41-4276-4f74-a5b6-c24f286a7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92061603-de62-4417-9e41-c6dfaf2c49aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c8ebd8-8d2e-429c-97e8-7d665c63b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cc5c7-3d51-4b2c-8eab-6937b3bef342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
